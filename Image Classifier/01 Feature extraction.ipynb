{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "**Feature Extraction**\n",
    "\n",
    "In this first part of the project, we start by extracting a set of high-level features for each image in the data set. To achieve this, we use MobileNet ConvNets which extract 1024 high-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the class label limit\n",
    "class_limit = 6\n",
    "\n",
    "# class names\n",
    "class_names = [\"bike\", \"car\", \"motorcycle\", \"other\", \"truck\", \"van\"]\n",
    "IMAGE_SIZE = 224\n",
    "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/laura/opt/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/laura/opt/anaconda3/lib/python3.7/site-packages (from keras) (1.17.2)\n",
      "Requirement already satisfied: h5py in /Users/laura/opt/anaconda3/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/laura/opt/anaconda3/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/laura/opt/anaconda3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/laura/opt/anaconda3/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/laura/opt/anaconda3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /Users/laura/opt/anaconda3/lib/python3.7/site-packages (from keras) (5.1.2)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6cdb0aac8180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# keras imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "\n",
    "! pip install keras\n",
    "# keras imports\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()  # Get the current working directory\n",
    "data_dir = os.path.join(base_dir, 'swissroads')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "valid_dir = os.path.join(data_dir, 'valid')\n",
    "\n",
    "\n",
    "# we are going to explore the content of the dataset by listing them using the listdir() method \n",
    "\n",
    "train_dir_content = os.listdir(train_dir)\n",
    "\n",
    "print(\"Number of Classes :\", len(train_dir_content))\n",
    "print(train_dir_content)\n",
    "\n",
    "current_class_name = train_dir_content[0]\n",
    "class_dir = os.path.join(train_dir, current_class_name)\n",
    "images_in_class = os.listdir(class_dir)\n",
    "\n",
    "print(\"Number of Samples in Class Named\", current_class_name, \":\" , len(images_in_class))\n",
    "\n",
    "image_file_dir = os.path.join(class_dir, images_in_class[0])\n",
    "\n",
    "print(\"Image Directory:\", image_file_dir)\n",
    "\n",
    "img = keras.preprocessing.image.load_img(image_file_dir)\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "print(img_array.shape, img_array.dtype)\n",
    "\n",
    "img_array = img_array/255.0\n",
    "\n",
    "plt.imshow(img_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read all training, testing, validation images in the dataset and read all images within a class in a single NumPy array. We do this according to the following steps:\n",
    "\n",
    "\n",
    "- Create an empty list to hold all images.\n",
    "- Loop through the classes within the respective directory.\n",
    "- Loop through the images within the class.\n",
    "- Read each image as a NumPy array.\n",
    "- Append the NumPy array to the list.\n",
    "- Convert the list into a NumPy array after all images are appended to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in Class Named car : 64\n",
      "Number of Samples in Class Named bike : 66\n",
      "Number of Samples in Class Named other : 32\n",
      "Number of Samples in Class Named van : 25\n",
      "Number of Samples in Class Named motorcycle : 51\n",
      "Number of Samples in Class Named truck : 42\n",
      "Training Data Array Shape : (280, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_array = []\n",
    "for current_class_name in train_dir_content:\n",
    "\n",
    "    class_dir = os.path.join(train_dir, current_class_name)\n",
    "    images_in_class = os.listdir(class_dir)\n",
    "\n",
    "    print(\"Number of Samples in Class Named\", current_class_name, \":\", len(images_in_class))\n",
    "\n",
    "    for image_file in images_in_class:\n",
    "        if image_file.endswith(\".png\"):\n",
    "            image_file_dir = os.path.join(class_dir, image_file)\n",
    "\n",
    "            img = keras.preprocessing.image.load_img(image_file_dir)\n",
    "            img_array = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "            img_array = img_array / 255.0\n",
    "            dataset_array.append(img_array)\n",
    "\n",
    "dataset_array = np.array(dataset_array)\n",
    "print(\"Training Data Array Shape :\", dataset_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a single function that accepts the path and returns the NumPy array for all images in all classes within it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_array(dataset_dir, image_size):\n",
    "    dataset_array = []\n",
    "    dataset_labels = []\n",
    "\n",
    "    class_counter = 0\n",
    "\n",
    "    classes_names = os.listdir(dataset_dir)\n",
    "    for current_class_name in classes_names:\n",
    "        class_dir = os.path.join(dataset_dir, current_class_name)\n",
    "        images_in_class = os.listdir(class_dir)\n",
    "\n",
    "        print(\"Class index\", class_counter, \", \", current_class_name, \":\" , len(images_in_class))\n",
    "\n",
    "        for image_file in images_in_class:\n",
    "            if image_file.endswith(\".png\"):\n",
    "                image_file_dir = os.path.join(class_dir, image_file)\n",
    "\n",
    "                img = keras.preprocessing.image.load_img(image_file_dir, target_size=(image_size, image_size))\n",
    "                img_array = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "#                 # scale pixel values to [0, 1]\n",
    "#                 img_array = img_array.astype('float32')\n",
    "\n",
    "                img_array = img_array/255.0\n",
    "\n",
    "                dataset_array.append(img_array)\n",
    "                dataset_labels.append(class_counter)\n",
    "        class_counter = class_counter + 1\n",
    "    dataset_array = np.array(dataset_array)\n",
    "    dataset_labels = np.array(dataset_labels)\n",
    "    return dataset_array, dataset_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images_to_array() function accepts 2 arguments:\n",
    "\n",
    "- dataset_dir: Path from which the images will be read.\n",
    "- image_size: Size of the image.\n",
    "\n",
    "The reason to pass the image_size as argument is that the MobileNet only works with pre-defined sizes of the input images. The dataset being handled must have its image size identical to the size expected by the MobileNet. Otherwise, an error will occur. Because the image size accepted by the MobileNet has the number of rows equal to the number of columns, then just a single value is passed to the image_size argument. When reading the image using the load_image() function in Keras, the target_size argument resizes the image automatically in the same step.\n",
    "\n",
    "By calling the images_to_array() function with the proper path, the images in that path and its child folders will be read and added to the NumPy array which will be returned by the function. In addition to the array that holds the images, there is another array named dataset_labels which holds the labels of the dataset.\n",
    "\n",
    "MobileNet accepts 4 image sizes which are 224, 192, 160, and 128. The image size for our dataset is 256x256. From the 4 sizes, 224 is the nearest, so we will use this one. The image shape now will be (224, 224, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index 0 ,  car : 64\n",
      "Class index 1 ,  bike : 66\n",
      "Class index 2 ,  other : 32\n",
      "Class index 3 ,  van : 25\n",
      "Class index 4 ,  motorcycle : 51\n",
      "Class index 5 ,  truck : 42\n",
      "Training Data Array Shape : (280, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_array, train_dataset_array_labels = images_to_array(dataset_dir=train_dir, image_size=IMAGE_SIZE)\n",
    "print(\"Training Data Array Shape :\", train_dataset_array.shape)\n",
    "np.save(\"train_dataset_array.npy\", train_dataset_array)\n",
    "np.save(\"train_dataset_array_labels.npy\", train_dataset_array_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index 0 ,  car : 11\n",
      "Class index 1 ,  bike : 12\n",
      "Class index 2 ,  other : 6\n",
      "Class index 3 ,  van : 5\n",
      "Class index 4 ,  motorcycle : 9\n",
      "Class index 5 ,  truck : 7\n",
      "Test Data Array Shape : (50, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test_dataset_array, test_dataset_array_labels = images_to_array(dataset_dir=test_dir, image_size=IMAGE_SIZE)\n",
    "print(\"Test Data Array Shape :\", test_dataset_array.shape)\n",
    "np.save(\"test_dataset_array.npy\", test_dataset_array)\n",
    "np.save(\"test_dataset_array_labels.npy\", test_dataset_array_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index 0 ,  car : 32\n",
      "Class index 1 ,  bike : 33\n",
      "Class index 2 ,  other : 16\n",
      "Class index 3 ,  van : 12\n",
      "Class index 4 ,  motorcycle : 25\n",
      "Class index 5 ,  truck : 21\n",
      "Validation Data Array Shape : (139, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "valid_dataset_array, valid_dataset_array_labels = images_to_array(dataset_dir=valid_dir, image_size=IMAGE_SIZE)\n",
    "print(\"Validation Data Array Shape :\", valid_dataset_array.shape)\n",
    "np.save(\"valid_dataset_array.npy\", valid_dataset_array)\n",
    "np.save(\"valid_dataset_array_labels.npy\", valid_dataset_array_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras supports a class named ImageDataGenerator for generating batches of tensor image data. It can also do real-time data augmentation. The next line creates an instance of the ImageDataGenerator class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to give this instance the data from which the batches will be generated. There are 2 main sources from which the data can be supplied which are:\n",
    "\n",
    "- Directory.\n",
    "- Pandas DataFrame.\n",
    "\n",
    "We are going to use the directory option, since the images are already prganized that way.\n",
    "\n",
    "For loading the data into the generator using the directory, then just use the flow_from_directory() method. This method accepts many arguments but only 2 of them must be specified in our experiment which are:\n",
    "\n",
    "- directory: Directory from which the images will be loaded for creating the batches.\n",
    "- target_size: Target size of the loaded image which is (256, 256) by default. This has to be changed to reflect the input size expected by MobileNet. We use (224, 224) as the image size, as per comments above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory=train_dir, target_size=(IMAGE_SIZE,IMAGE_SIZE))\n",
    "test_generator = train_datagen.flow_from_directory(directory=test_dir, target_size=(IMAGE_SIZE,IMAGE_SIZE))\n",
    "valid_generator = train_datagen.flow_from_directory(directory=valid_dir, target_size=(IMAGE_SIZE,IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow has a module tensorflow.keras.applications which holds a number of pre-trained deep learning models.\n",
    "\n",
    "To inform the network that it will not be retrained, the trainable parameter of the loaded model is set to False. This indicates that no layer will be trained.\n",
    "\n",
    "Here we added just 2 layers at the top of the architecture. The newly added 2 layers are trainable by default. We could add more layers but this increases the number of trainable parameters and thus requires more time for transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 102)               104550    \n",
      "=================================================================\n",
      "Total params: 3,333,414\n",
      "Trainable params: 104,550\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNet(input_shape=IMAGE_SHAPE, include_top=False)\n",
    "base_model.trainable = False\n",
    "base_model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(102, activation='sigmoid')\n",
    "])\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras offers a class named Model. The constructor of this class accepts 2 arguments which are an input tensor and an output tensor. \n",
    "\n",
    "In our case, we will feed the Model class constructor by our model inputs and the outputs from the desired layer as given in the next line. The inputs argument is assigned to the model input which is returned using the input property. Because the desired layer to return its outputs is the pooling layer named global_average_pooling2d, then the outputs from this layer are assigned to the outputs argument. This layer is returned using the get_layer() method and its output is returned using the output property. If you want to build a model that returns the output of another layer when the predict() method is called, then specify its name in the get_layer() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Model(inputs=base_model.input, outputs=base_model.get_layer('global_average_pooling2d').output)\n",
    "train_dataset_array = np.load(\"train_dataset_array.npy\")\n",
    "train_dataset_array_labels = np.load(\"train_dataset_array_labels.npy\")\n",
    "\n",
    "features = model2.predict(train_dataset_array[0:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to extract the features from the entire training data, just pass the train_dataset_array NumPy array to the predict() method as given in the next code. The extracted features from the training images are saved in the training_features NumPy array. The shape of this array is (280, 1,024) because there are 280 training images and a feature vector of length 1,024 is extracted from each image. Finally, this NumPy array is saved in an npy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 1024)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_array = np.load(\"train_dataset_array.npy\")\n",
    "\n",
    "train_features = model2.predict(train_dataset_array)\n",
    "base_model = np.save('train_features.npy', train_features)\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1024)\n"
     ]
    }
   ],
   "source": [
    "test_dataset_array = np.load(\"test_dataset_array.npy\")\n",
    "\n",
    "test_features = model2.predict(test_dataset_array)\n",
    "base_model = np.save('test_features.npy', test_features)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 1024)\n"
     ]
    }
   ],
   "source": [
    "valid_dataset_array = np.load(\"valid_dataset_array.npy\")\n",
    "\n",
    "valid_features = model2.predict(valid_dataset_array)\n",
    "base_model = np.save('valid_features.npy', valid_features)\n",
    "print(valid_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
