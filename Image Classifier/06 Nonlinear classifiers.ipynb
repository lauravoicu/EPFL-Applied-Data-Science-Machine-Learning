{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "**Nonlinear classifiers**\n",
    "\n",
    "Try with nonlinear classifiers, can you do better than the baseline models from above?\n",
    "\n",
    "- Try with a random Forest, does increasing the number of trees help?\n",
    "- Try with SVMs - does the RBF kernel perform better than the linear one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the class label limit\n",
    "class_limit = 6\n",
    "\n",
    "# class names\n",
    "class_names = [\"car\", \"bike\", \"other\", \"van\", \"motorcycle\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the numpy .npy file\n",
    "train_dataset_array = np.load(\"train_dataset_array.npy\")\n",
    "train_dataset_array_labels = np.load(\"train_dataset_array_labels.npy\")\n",
    "train_dataset_array_features = np.load(\"train_features.npy\")\n",
    "\n",
    "print('Train data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the numpy .npy file\n",
    "test_dataset_array = np.load(\"test_dataset_array.npy\")\n",
    "test_dataset_array_labels = np.load(\"test_dataset_array_labels.npy\")\n",
    "test_dataset_array_features = np.load(\"test_features.npy\")\n",
    "\n",
    "print('Test data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the numpy .npy file\n",
    "valid_dataset_array = np.load(\"valid_dataset_array.npy\")\n",
    "valid_dataset_array_labels = np.load(\"valid_dataset_array_labels.npy\")\n",
    "valid_dataset_array_features = np.load(\"valid_features.npy\")\n",
    "\n",
    "print('Validation data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (280, 1024) float32\n",
      "y: (280,) int64\n"
     ]
    }
   ],
   "source": [
    "# Create X/y arrays\n",
    "X_tr = train_dataset_array_features\n",
    "y_tr = train_dataset_array_labels\n",
    "\n",
    "print('X:', X_tr.shape, X_tr.dtype)\n",
    "print('y:', y_tr.shape, y_tr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (50, 1024) float32\n",
      "y: (50,) int64\n"
     ]
    }
   ],
   "source": [
    "# Create X/y arrays\n",
    "X_te = test_dataset_array_features\n",
    "y_te = test_dataset_array_labels\n",
    "\n",
    "print('X:', X_te.shape, X_te.dtype)\n",
    "print('y:', y_te.shape, y_te.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val: (139, 1024) float32\n",
      "y_val: (139,) int64\n"
     ]
    }
   ],
   "source": [
    "# Create X/y arrays\n",
    "X_val = valid_dataset_array_features\n",
    "y_val = valid_dataset_array_labels\n",
    "\n",
    "print('X_val:', X_val.shape, X_val.dtype)\n",
    "print('y_val:', y_val.shape, y_val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.235714\n",
       "0    0.228571\n",
       "4    0.182143\n",
       "5    0.150000\n",
       "2    0.114286\n",
       "3    0.089286\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y_tr, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(number):\n",
    "    # conversion \n",
    "    if number==0 : return 'car'\n",
    "    #                             \n",
    "    if number==1 : return 'bike'\n",
    "    #                             \n",
    "    if number==2 : return 'other'\n",
    "    #                             \n",
    "    if number==3 : return 'van'\n",
    "    #                             \n",
    "    if number==4 : return 'motorcycle'\n",
    "    #                             \n",
    "    if number==5 : return 'truck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't use PCA since random forrests are not that prone to overfitting\n",
    "pipe = Pipeline([('pca', None),\n",
    "                 ('forest', RandomForestClassifier(n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible combinations: 3 \n"
     ]
    }
   ],
   "source": [
    "# We try different numbers of estimators \n",
    "estimators = [1000, 1500, 2000]\n",
    "\n",
    "grid = ParameterGrid({'forest__n_estimators': estimators,\n",
    "                     })\n",
    "print ('Possible combinations: {} '.format(len(grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_forrest_scores = []\n",
    "\n",
    "for params_dict in grid:\n",
    "    pipe.set_params(**params_dict)\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    params_dict['accuracy'] = pipe.score(X_val, y_val)\n",
    "    val_forrest_scores.append(params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forest__n_estimators</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.834532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.827338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.820144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   forest__n_estimators  accuracy\n",
       "0                  1000  0.834532\n",
       "1                  1500  0.827338\n",
       "2                  2000  0.820144"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top validation-scores\n",
    "forest_df = pd.DataFrame(val_forrest_scores)\n",
    "forest_df.sort_values(by='accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy in the train set: 0.8345323741007195 with 1000 estimators\n"
     ]
    }
   ],
   "source": [
    "best_forrest = forest_df['accuracy'].idxmax()\n",
    "print ('Best accuracy in the train set: {} with {} estimators'\n",
    "       .format(forest_df.loc[best_forrest, 'accuracy'], forest_df.loc[best_forrest, 'forest__n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy on validation set: 0.820\n",
      "Random forest accuracy on test set: 0.880\n"
     ]
    }
   ],
   "source": [
    "# Tuned Forrest\n",
    "forest = RandomForestClassifier(n_estimators = forest_df.loc[best_forrest,'forest__n_estimators'], n_jobs=-1)\n",
    "pipe = Pipeline([('pca', None),\n",
    "                 ('forest', forest)])\n",
    "\n",
    "pipe.fit(X_tr, y_tr)\n",
    "acc_forest_val = pipe.score(X_val, y_val)\n",
    "print ('Random forest accuracy on validation set: {:.3f}'.format(acc_forest_val))\n",
    "acc_forest_te = pipe.score(X_te, y_te)\n",
    "print ('Random forest accuracy on test set: {:.3f}'.format(acc_forest_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use PCA to speed up processing and prevent overfitting. We set it to 150 retaining 90+% of the variance\n",
    "pca = PCA(n_components=150)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('linearsvc', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laura/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pca',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=150, random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('linearsvc',\n",
       "                                        LinearSVC(C=1.0, class_weight=None,\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'linearsvc__C': [0.0001, 0.001, 0.01, 0.1, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv = GridSearchCV(pipe, {'linearsvc__C':[0.0001, 0.001,0.01,0.1,1,]}, \n",
    "                       cv=5,\n",
    "                       n_jobs=-1\n",
    "                      )\n",
    "\n",
    "grid_cv.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_linearsvc__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.092350</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'linearsvc__C': 0.0001}</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.036805</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.071265</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'linearsvc__C': 0.001}</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098249</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'linearsvc__C': 0.01}</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.014349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.144099</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'linearsvc__C': 0.1}</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.015662</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.183563</td>\n",
       "      <td>0.031701</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>1</td>\n",
       "      <td>{'linearsvc__C': 1}</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.092350      0.006627         0.002146        0.000169   \n",
       "1       0.071265      0.004613         0.001838        0.000312   \n",
       "2       0.098249      0.007711         0.001699        0.000146   \n",
       "3       0.144099      0.007527         0.001699        0.000299   \n",
       "4       0.183563      0.031701         0.001394        0.000367   \n",
       "\n",
       "  param_linearsvc__C                    params  split0_test_score  \\\n",
       "0             0.0001  {'linearsvc__C': 0.0001}           0.864407   \n",
       "1              0.001   {'linearsvc__C': 0.001}           0.898305   \n",
       "2               0.01    {'linearsvc__C': 0.01}           0.881356   \n",
       "3                0.1     {'linearsvc__C': 0.1}           0.864407   \n",
       "4                  1       {'linearsvc__C': 1}           0.898305   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.842105           0.781818           0.854545           0.777778   \n",
       "1           0.877193           0.872727           0.909091           0.888889   \n",
       "2           0.894737           0.854545           0.890909           0.888889   \n",
       "3           0.877193           0.872727           0.909091           0.870370   \n",
       "4           0.877193           0.872727           0.909091           0.870370   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.825000        0.036805                5  \n",
       "1         0.889286        0.013336                1  \n",
       "2         0.882143        0.014349                3  \n",
       "3         0.878571        0.015662                4  \n",
       "4         0.885714        0.015299                2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lin_svp = pd.DataFrame(grid_cv.cv_results_)\n",
    "df_lin_svp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean test accuracy was 0.889 with a C value of 0.001\n"
     ]
    }
   ],
   "source": [
    "best = df_lin_svp['mean_test_score'].idxmax()\n",
    "\n",
    "print('Best mean test accuracy was {:.3f} with a C value of {}'\n",
    "      .format(df_lin_svp.loc[best, 'mean_test_score'], \n",
    "              df_lin_svp.loc[best, 'param_linearsvc__C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.975\n",
      "Accuracy on test set: 0.920\n",
      "Accuracy on validation set: 0.863\n"
     ]
    }
   ],
   "source": [
    "# Seeing the metrics\n",
    "print(\"Accuracy on training set: {:.3f}\".format(grid_cv.score(X_tr, y_tr)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(grid_cv.score(X_te, y_te)))\n",
    "print(\"Accuracy on validation set: {:.3f}\".format(grid_cv.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_rbf = SVC(kernel='rbf', random_state=0)\n",
    "\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('svc_rbf', svc_rbf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laura/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pca',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=150, random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('svc_rbf',\n",
       "                                        SVC(C=1.0, cache_size=200,\n",
       "                                            class_weight=None, coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='auto_deprecated',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False, random_state=0,\n",
       "                                            shrinking=True, tol=0.001,\n",
       "                                            verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'svc_rbf__C': [0.01, 0.1, 1, 10],\n",
       "                         'svc_rbf__gamma': [0.0001, 0.001, 0.01, 0.1, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_rbf = GridSearchCV(pipe, {'svc_rbf__C':[0.01, 0.1, 1, 10], \n",
    "                                  'svc_rbf__gamma':[0.0001, 0.001, 0.01, 0.1, 1]}, \n",
    "                           cv=5,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_cv_rbf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svc_rbf__C</th>\n",
       "      <th>param_svc_rbf__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.081561</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'svc_rbf__C': 0.01, 'svc_rbf__gamma': 0.0001}</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.22807</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.235714</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.083021</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'svc_rbf__C': 0.01, 'svc_rbf__gamma': 0.001}</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.22807</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.235714</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.081290</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'svc_rbf__C': 0.01, 'svc_rbf__gamma': 0.01}</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.22807</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.235714</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.082771</td>\n",
       "      <td>0.005957</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'svc_rbf__C': 0.01, 'svc_rbf__gamma': 0.1}</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.22807</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.235714</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'svc_rbf__C': 0.01, 'svc_rbf__gamma': 1}</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.22807</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.235714</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.081561      0.004201         0.005939        0.001944   \n",
       "1       0.083021      0.003099         0.004508        0.000307   \n",
       "2       0.081290      0.003831         0.004555        0.000458   \n",
       "3       0.082771      0.005957         0.005428        0.001609   \n",
       "4       0.083881      0.012555         0.005118        0.000788   \n",
       "\n",
       "  param_svc_rbf__C param_svc_rbf__gamma  \\\n",
       "0             0.01               0.0001   \n",
       "1             0.01                0.001   \n",
       "2             0.01                 0.01   \n",
       "3             0.01                  0.1   \n",
       "4             0.01                    1   \n",
       "\n",
       "                                           params  split0_test_score  \\\n",
       "0  {'svc_rbf__C': 0.01, 'svc_rbf__gamma': 0.0001}           0.237288   \n",
       "1   {'svc_rbf__C': 0.01, 'svc_rbf__gamma': 0.001}           0.237288   \n",
       "2    {'svc_rbf__C': 0.01, 'svc_rbf__gamma': 0.01}           0.237288   \n",
       "3     {'svc_rbf__C': 0.01, 'svc_rbf__gamma': 0.1}           0.237288   \n",
       "4       {'svc_rbf__C': 0.01, 'svc_rbf__gamma': 1}           0.237288   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0            0.22807           0.236364           0.236364           0.240741   \n",
       "1            0.22807           0.236364           0.236364           0.240741   \n",
       "2            0.22807           0.236364           0.236364           0.240741   \n",
       "3            0.22807           0.236364           0.236364           0.240741   \n",
       "4            0.22807           0.236364           0.236364           0.240741   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.235714        0.004178                8  \n",
       "1         0.235714        0.004178                8  \n",
       "2         0.235714        0.004178                8  \n",
       "3         0.235714        0.004178                8  \n",
       "4         0.235714        0.004178                8  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rbf_svp = pd.DataFrame(grid_cv_rbf.cv_results_)\n",
    "df_rbf_svp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy 0.900 with a C value of 10 and a gamma of 0.001\n"
     ]
    }
   ],
   "source": [
    "best = df_rbf_svp['mean_test_score'].idxmax()\n",
    "\n",
    "print('Best accuracy {:.3f} with a C value of {} and a gamma of {}'\n",
    "      .format(df_rbf_svp.loc[best, 'mean_test_score'], \n",
    "              df_rbf_svp.loc[best, 'param_svc_rbf__C'], \n",
    "              df_rbf_svp.loc[best, 'param_svc_rbf__gamma'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.920\n",
      "Accuracy on validation set: 0.899\n"
     ]
    }
   ],
   "source": [
    "# Seeing the metrics\n",
    "print(\"Accuracy on training set: {:.3f}\".format(grid_cv_rbf.score(X_tr, y_tr)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(grid_cv_rbf.score(X_te, y_te)))\n",
    "print(\"Accuracy on validation set: {:.3f}\".format(grid_cv_rbf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (most frequent) accuracy on training set 0.236\n",
      "Baseline (most frequent) accuracy on test set 0.240\n"
     ]
    }
   ],
   "source": [
    "# Getting a baseline-accuracy based on the most frequent category\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_tr, y_tr)\n",
    "accuracy_tr = dummy.score(X_tr, y_tr)\n",
    "accuracy_te = dummy.score(X_te, y_te)\n",
    "\n",
    "print('Baseline (most frequent) accuracy on training set {:.3f}'.format(accuracy_tr))\n",
    "print('Baseline (most frequent) accuracy on test set {:.3f}'.format(accuracy_te))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
